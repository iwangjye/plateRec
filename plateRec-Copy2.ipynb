{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import caffe\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#图像保持比例放大或缩小\n",
    "class PreprocessResizeKeepRatio(object):\n",
    "\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def do(self, cv2_img):\n",
    "        max_width = self.width\n",
    "        max_height = self.height\n",
    "\n",
    "        cur_height, cur_width = cv2_img.shape[:2]#当前图像尺寸\n",
    "        if float(cur_width)!=0 and float(cur_height)!=0:\n",
    "            ratio_w = float(max_width)/float(cur_width)\n",
    "            ratio_h = float(max_height)/float(cur_height)\n",
    "            ratio = min(ratio_w, ratio_h)\n",
    "\n",
    "            new_size = (min(int(cur_width*ratio), max_width),\n",
    "                        min(int(cur_height*ratio), max_height))\n",
    "\n",
    "            new_size = (max(new_size[0], 1),\n",
    "                        max(new_size[1], 1),)\n",
    "\n",
    "            resized_img = cv2.resize(cv2_img, new_size)\n",
    "            return resized_img\n",
    "        return cv2_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#取峰值\n",
    "def extract_peek_ranges_from_array_x(array_vals, minimun_val=20000, minimun_range=150):\n",
    "    \"\"\"\n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    peek_ranges = []\n",
    "    for i, val in enumerate(array_vals):\n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        if val > minimun_val:\n",
    "            end_i = i\n",
    "                      \n",
    "    peek_ranges.append((start_i, end_i))    \n",
    "    return peek_ranges\n",
    "    \"\"\"\n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    peek_ranges = []\n",
    "    for i, val in enumerate(array_vals):\n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        elif val > minimun_val and start_i is not None:\n",
    "            #end_i = i\n",
    "            pass\n",
    "        elif val < minimun_val and start_i is not None:\n",
    "            end_i = i\n",
    "            if end_i - start_i <= minimun_range:\n",
    "                start_i = None\n",
    "                end_i = None\n",
    "                #peek_ranges.append((start_i, end_i))\n",
    "            else:\n",
    "                end_i = i\n",
    "                break;\n",
    "        elif val < minimun_val and start_i is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"cannot parse this case...\")\n",
    "    if end_i == None:\n",
    "        end_i = 250\n",
    "    peek_ranges.append((start_i, end_i))\n",
    "    return peek_ranges\n",
    "\n",
    "\n",
    "def extract_peek_ranges_from_array_y(array_vals, minimun_val=2000, minimun_range=10):\n",
    "    left_i = None\n",
    "    right_i = None\n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    length = len(array_vals)\n",
    "    peek_ranges = []\n",
    "    for i, val in enumerate(array_vals):\n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        elif val > minimun_val and start_i is not None:\n",
    "            pass\n",
    "        elif val < minimun_val and start_i is not None:\n",
    "            end_i = i\n",
    "            if end_i - start_i <= minimun_range:\n",
    "                start_i = None\n",
    "                end_i = None\n",
    "                #peek_ranges.append((start_i, end_i))\n",
    "            else:\n",
    "                left_i = start_i\n",
    "                break;\n",
    "        elif val < minimun_val and start_i is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"cannot parse this case...\")\n",
    "\n",
    "    for i, val in enumerate(array_vals[::-1]):\n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        elif val > minimun_val and start_i is not None:\n",
    "            pass\n",
    "        elif val < minimun_val and start_i is not None:\n",
    "            end_i = i\n",
    "            if end_i - start_i <= minimun_range:\n",
    "                start_i = None\n",
    "                end_i = None\n",
    "                #peek_ranges.append((start_i, end_i))\n",
    "            else:\n",
    "                right_i = length - start_i\n",
    "                break;\n",
    "        elif val < minimun_val and start_i is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"cannot parse this case...\")\n",
    "\n",
    "    #peek_ranges.append((left_i, right_i))\n",
    "    if right_i == None:\n",
    "        right_i = 980\n",
    "    if left_i == None:\n",
    "        left_i = 20\n",
    "    width = int((right_i-left_i)/7.5)\n",
    "    for i in range(2):\n",
    "        start_i = left_i+width*i\n",
    "        end_i = left_i+width*(i+1)\n",
    "        peek_ranges.append((start_i, end_i))\n",
    "        # peek_ranges.append((start_i-((i+1)*2), end_i-((i+1)*2)))\n",
    "    for i in range(5):\n",
    "        start_i = right_i-width*(i+1)\n",
    "        end_i = right_i-width*i\n",
    "        peek_ranges.append((start_i-(i*2), end_i-(i*2)))\n",
    "    return peek_ranges\n",
    "\n",
    "def extract_peek_ranges_from_array_single(array_vals, minimun_val=1000, minimun_range=10):\n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    peek_ranges = []\n",
    "    for i, val in enumerate(array_vals):\n",
    "        if val > minimun_val and start_i is None:\n",
    "            start_i = i\n",
    "        elif val > minimun_val and start_i is not None:\n",
    "            #end_i = i\n",
    "            pass\n",
    "        elif val < minimun_val and start_i is not None:\n",
    "            end_i = i\n",
    "            if end_i - start_i <= minimun_range:\n",
    "                start_i = None\n",
    "                end_i = None\n",
    "                #peek_ranges.append((start_i, end_i))\n",
    "            else:\n",
    "                end_i = i\n",
    "                break;\n",
    "        elif val < minimun_val and start_i is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"cannot parse this case...\")\n",
    "    if end_i == None:\n",
    "        end_i = 250\n",
    "    peek_ranges.append((start_i, end_i))\n",
    "    return peek_ranges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Draw\n",
    "def draw_rectangle(color_img, peek_ranges, vertical_peek_ranges2d):\n",
    "    \n",
    "    color = (255, 0, 0)\n",
    "    for i, peek_range in enumerate(peek_ranges):#行\n",
    "        for vertical_range in vertical_peek_ranges2d[i]:#列\n",
    "            x = vertical_range[0]\n",
    "            y = peek_range[0]\n",
    "            w = vertical_range[1] - x\n",
    "            h = peek_range[1] - y\n",
    "            pt1 = (x, y)\n",
    "            pt2 = (x + w, y + h)\n",
    "            cv2.rectangle(color_img, pt1, pt2, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try to find text lines and chars\n",
    "def crop_direct(peek_ranges, adaptive_image, debug = False):   \n",
    "    vertical_peek_ranges2d = []\n",
    "    for peek_range in peek_ranges:\n",
    "        start_y = peek_range[0]\n",
    "        end_y = peek_range[1]\n",
    "        line_img = adaptive_image[start_y:end_y, :]\n",
    "        vertical_sum = np.sum(line_img, axis=0)\n",
    "        vertical_peek_ranges = extract_peek_ranges_from_array_y(\n",
    "            vertical_sum)\n",
    "        #vertical_peek_ranges = median_split_ranges(vertical_peek_ranges)#利用中位数再次切割     \n",
    "        vertical_peek_ranges2d.append(vertical_peek_ranges)\n",
    "    return vertical_peek_ranges2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 求一行的中位数宽度\n",
    "def compute_median_w_from_ranges(peek_ranges):\n",
    "    widthes = []\n",
    "    for peek_range in peek_ranges:\n",
    "        w = peek_range[1] - peek_range[0] + 1\n",
    "        widthes.append(w)\n",
    "    widthes = np.asarray(widthes)\n",
    "    median_w = np.median(widthes)\n",
    "    return median_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_symbol(num_image, array_vals, cur_h, minimun_val=3, h_ratio=0.4):\n",
    "    start_i = None\n",
    "    end_i = None\n",
    "    for i, val in enumerate(array_vals):\n",
    "        if val > minimun_val:      \n",
    "            if i > cur_h*h_ratio:\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_noise(peek_ranges, vertical_peek_ranges2d, adaptive_image, stan_w_ratio = 0.4, debug = True):#ratio:\n",
    "    filtered_vertical_peek_ranges2d = []\n",
    "    num_image = 0\n",
    "    for i, peek_range in enumerate(peek_ranges):\n",
    "        new_peek_range = []\n",
    "        median_w = compute_median_w_from_ranges(vertical_peek_ranges2d[i])\n",
    "        stan_w = median_w * stan_w_ratio\n",
    "        cur_h = peek_range[1] - peek_range[0]\n",
    "        for j, vertical_range in enumerate(vertical_peek_ranges2d[i]):\n",
    "            cur_w = vertical_range[1] - vertical_range[0]\n",
    "            if cur_w < stan_w and cur_w > 0.1*median_w:\n",
    "                char_image = adaptive_image[peek_range[0]:peek_range[1], vertical_range[0]:vertical_range[1]]          \n",
    "                horizontal_sum = np.sum(char_image, axis=1)\n",
    "                num_image += 1\n",
    "                if debug:\n",
    "                    plt.subplot(20, 10, num_image)\n",
    "                    plt.imshow(char_image)\n",
    "                if is_symbol(num_image, horizontal_sum, cur_h):\n",
    "                    plt.title(str(num_image)+':True')\n",
    "                else:\n",
    "                    plt.title(str(num_image)+':False')\n",
    "                    new_peek_range.append(vertical_range)                              \n",
    "            elif cur_w >= stan_w:\n",
    "                new_peek_range.append(vertical_range)\n",
    "            else:\n",
    "                pass\n",
    "        filtered_vertical_peek_ranges2d.append(new_peek_range)\n",
    "    return filtered_vertical_peek_ranges2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 求一行的中位数宽度\n",
    "def compute_median_w_from_ranges(peek_ranges):\n",
    "    widthes = []\n",
    "    for peek_range in peek_ranges:\n",
    "        w = peek_range[1] - peek_range[0] + 1\n",
    "        widthes.append(w)\n",
    "    widthes = np.asarray(widthes)\n",
    "    median_w = np.median(widthes)\n",
    "    return median_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_char(peek_ranges, vertical_peek_ranges2d, ratio = 0.8):##eg:似\n",
    "    filtered_vertical_peek_ranges2d = []\n",
    "    for i, peek_range in enumerate(peek_ranges):\n",
    "        new_peek_range = []\n",
    "        median_w = compute_median_w_from_ranges(vertical_peek_ranges2d[i])\n",
    "        stan_w = median_w * ratio\n",
    "        last_w = None#用来记录上一个区间的宽度\n",
    "        length = len(vertical_peek_ranges2d[i])\n",
    "        for j, vertical_range in enumerate(vertical_peek_ranges2d[i]):\n",
    "            cur_w = vertical_range[1] - vertical_range[0]\n",
    "            if cur_w < stan_w and cur_w > median_w*0.1:\n",
    "                if last_w != None:\n",
    "                    if cur_w > median_w*0.5:\n",
    "                        new_node = (vertical_peek_ranges2d[i][j-1][0],vertical_peek_ranges2d[i][j][1])#连续两个非正常区间合并\n",
    "                        new_peek_range.append(new_node)\n",
    "                        last_w = None\n",
    "                    else:\n",
    "                        new_node_last = (vertical_peek_ranges2d[i][j-1][0],vertical_peek_ranges2d[i][j-1][1])#连续两个非正常区间合并\n",
    "                        new_peek_range.append(new_node_last)\n",
    "                        new_node_new = (vertical_peek_ranges2d[i][j][0],vertical_peek_ranges2d[i][j][1])#连续两个非正常区间合并\n",
    "                        new_peek_range.append(new_node_new)\n",
    "                else:\n",
    "                    last_w = True\n",
    "            else:\n",
    "                if last_w != None:\n",
    "                    new_node_last = (vertical_peek_ranges2d[i][j-1][0],vertical_peek_ranges2d[i][j-1][1])#连续两个非正常区间合并\n",
    "                    new_peek_range.append(new_node_last)\n",
    "                    new_node_new = (vertical_peek_ranges2d[i][j][0],vertical_peek_ranges2d[i][j][1])#连续两个非正常区间合并\n",
    "                    new_peek_range.append(new_node_new)\n",
    "                else:\n",
    "                    \n",
    "                    new_peek_range.append(vertical_range)\n",
    "                last_w = None\n",
    "            if j+1 == length and cur_w < stan_w and last_w==True:\n",
    "                new_peek_range.append(vertical_range)\n",
    "        filtered_vertical_peek_ranges2d.append(new_peek_range)\n",
    "    return filtered_vertical_peek_ranges2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_regular(peek_ranges, vertical_peek_ranges2d, adaptive_image):\n",
    "    filtered_vertical_peek_ranges2d = []\n",
    "    for i, peek_range in enumerate(peek_ranges):\n",
    "        new_peek_range = []\n",
    "        for j, vertical_range in enumerate(vertical_peek_ranges2d[i]):\n",
    "            start_x = peek_range[0]\n",
    "            end_x = peek_range[1]\n",
    "            line_img = adaptive_image[start_x:end_x, :]\n",
    "            vertical_sum = np.sum(line_img, axis=0)\n",
    "            vertical_peek_range = extract_peek_ranges_from_array_single(vertical_sum)\n",
    "            new_peek_range.append(vertical_peek_range)\n",
    "    filtered_vertical_peek_ranges2d.append(new_peek_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CaffeCls(object):\n",
    "    def __init__(self, \n",
    "                 model_def,\n",
    "                 model_weights,\n",
    "                 y_tag_json_path,\n",
    "                 is_mode_cpu=True,\n",
    "                 width=64,\n",
    "                 height=64):\n",
    "        self.net = caffe.Net(model_def,\n",
    "            model_weights,\n",
    "            caffe.TEST)\n",
    "        if is_mode_cpu:\n",
    "            caffe.set_mode_cpu()\n",
    "        self.y_tag_json = json.load(open(y_tag_json_path, \"r\"))\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def _predict_cv2_imgs_sub(self, cv2_imgs, pos_start, pos_end):\n",
    "        cv2_imgs_sub = cv2_imgs[pos_start: pos_end]\n",
    "        #if cv2_imgs_sub[0][0][0] > 1.0:\n",
    "            #raise ValueError(\"image should be normalized between 0 and 1.0\")\n",
    "        self.net.blobs['data'].reshape(cv2_imgs_sub.shape[0], 1,\n",
    "                                       self.width, self.height)\n",
    "        self.net.blobs['data'].data[...] = cv2_imgs_sub.reshape(\n",
    "            (cv2_imgs_sub.shape[0], 1, self.width, self.height))\n",
    "\n",
    "        output = self.net.forward()\n",
    "        output_tag_to_max_proba = []\n",
    "        \n",
    "        num_sample = cv2_imgs_sub.shape[0]\n",
    "        for i in range(num_sample):\n",
    "            output_prob = output['prob'][i]\n",
    "            output_prob_index = sorted(\n",
    "                range(len(output_prob)),\n",
    "                key=lambda x:output_prob[x],\n",
    "                reverse=True)            \n",
    "            output_tag_to_probas = []\n",
    "            for index in output_prob_index:\n",
    "                item = (self.y_tag_json[str(index)],\n",
    "                        output_prob[index])\n",
    "                output_tag_to_probas.append(item)\n",
    "            # output_tag_to_probas = output_tag_to_probas[:2]\n",
    "            output_tag_to_max_proba.append(output_tag_to_probas)\n",
    "        return output_tag_to_max_proba\n",
    "\n",
    "    def predict_cv2_imgs(self, cv2_imgs, step=50):\n",
    "        output_tag_to_max_proba = []\n",
    "        num_sample = cv2_imgs.shape[0]\n",
    "        for i in range(0, num_sample, step):\n",
    "            pos_end = min(num_sample, (i + step))\n",
    "            output_tag_to_max_proba += \\\n",
    "                self._predict_cv2_imgs_sub(cv2_imgs, i, pos_end)\n",
    "        return output_tag_to_max_proba\n",
    "\n",
    "    def predict_cv2_img(self, cv2_img):\n",
    "        shape = cv2_img.shape\n",
    "        cv2_imgs = cv2_img.reshape((1, shape[0], shape[1]))\n",
    "        return self.predict_cv2_imgs(cv2_imgs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PreprocessCropZeros(object):#四个方向切一遍\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def do(self, cv2_gray_img):\n",
    "        height = cv2_gray_img.shape[0]\n",
    "        width = cv2_gray_img.shape[1]\n",
    "\n",
    "        v_sum = np.sum(cv2_gray_img, axis=0)\n",
    "        h_sum = np.sum(cv2_gray_img, axis=1)\n",
    "        left = 0\n",
    "        right = width - 1\n",
    "        top = 0\n",
    "        low = height - 1\n",
    "\n",
    "        for i in range(width):\n",
    "            if v_sum[i] > 30:\n",
    "                left = i\n",
    "                break\n",
    "\n",
    "        for i in range(width - 1, -1, -1):\n",
    "            if v_sum[i] > 300:\n",
    "                right = i\n",
    "                break\n",
    "\n",
    "        for i in range(height):\n",
    "            if h_sum[i] > 30:\n",
    "                top = i\n",
    "                break\n",
    "\n",
    "        for i in range(height - 1, -1, -1):\n",
    "            if h_sum[i] > 30:\n",
    "                low = i\n",
    "                break\n",
    "        if not (top < low and right > left):\n",
    "            return cv2_gray_img\n",
    "\n",
    "        return cv2_gray_img[top: low+1, left: right+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PreprocessResizeKeepRatioFillBG(object):\n",
    "\n",
    "    def __init__(self, width, height, fill_bg=False,\n",
    "                 auto_avoid_fill_bg=True, margin=None):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fill_bg = fill_bg\n",
    "        self.auto_avoid_fill_bg = auto_avoid_fill_bg\n",
    "        self.margin = margin\n",
    "\n",
    "    @classmethod\n",
    "    def is_need_fill_bg(cls, cv2_img, th=0.5, max_val=255):\n",
    "        image_shape = cv2_img.shape\n",
    "        height, width = image_shape\n",
    "        if height * 3 < width:\n",
    "            return True\n",
    "        if width * 3 < height:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def put_img_into_center(cls, img_large, img_small, ):\n",
    "        width_large = img_large.shape[1]\n",
    "        height_large = img_large.shape[0]\n",
    "\n",
    "        width_small = img_small.shape[1]\n",
    "        height_small = img_small.shape[0]\n",
    "\n",
    "        if width_large < width_small:\n",
    "            #raise ValueError(\"width_large <= width_small\")\n",
    "            return img_large\n",
    "        if height_large < height_small:\n",
    "            #raise ValueError(\"height_large <= height_small\")\n",
    "            return img_large\n",
    "\n",
    "        start_width = (width_large - width_small) / 2\n",
    "        start_height = (height_large - height_small) / 2\n",
    "\n",
    "        img_large[start_height:start_height + height_small,\n",
    "                  start_width:start_width + width_small] = img_small\n",
    "        return img_large\n",
    "\n",
    "    def do(self, cv2_img):\n",
    "\n",
    "        if self.margin is not None:\n",
    "            width_minus_margin = max(2, self.width - self.margin)\n",
    "            height_minus_margin = max(2, self.height - self.margin)\n",
    "        else:\n",
    "            width_minus_margin = self.width\n",
    "            height_minus_margin = self.height\n",
    "\n",
    "        cur_height, cur_width = cv2_img.shape[:2]\n",
    "        if len(cv2_img.shape) > 2:\n",
    "            pix_dim = cv2_img.shape[2]\n",
    "        else:\n",
    "            pix_dim = None\n",
    "\n",
    "        preprocess_resize_keep_ratio = PreprocessResizeKeepRatio(\n",
    "            width_minus_margin,\n",
    "            height_minus_margin)\n",
    "        resized_cv2_img = preprocess_resize_keep_ratio.do(cv2_img)\n",
    "\n",
    "        if self.auto_avoid_fill_bg:\n",
    "            need_fill_bg = self.is_need_fill_bg(cv2_img)\n",
    "            if not need_fill_bg:\n",
    "                self.fill_bg = False\n",
    "            else:\n",
    "                self.fill_bg = True\n",
    "\n",
    "        ## should skip horizontal stroke\n",
    "        if not self.fill_bg:\n",
    "            ret_img = cv2.resize(resized_cv2_img, (width_minus_margin,\n",
    "                                                   height_minus_margin))\n",
    "        else:\n",
    "            if pix_dim is not None:\n",
    "                norm_img = np.zeros((height_minus_margin,\n",
    "                                     width_minus_margin,\n",
    "                                     pix_dim),\n",
    "                                    np.uint8)\n",
    "            else:\n",
    "                norm_img = np.zeros((height_minus_margin,\n",
    "                                     width_minus_margin),\n",
    "                                    np.uint8)\n",
    "            ret_img = self.put_img_into_center(norm_img, resized_cv2_img)\n",
    "\n",
    "        if self.margin is not None:\n",
    "            if pix_dim is not None:\n",
    "                norm_img = np.zeros((self.height,\n",
    "                                     self.width,\n",
    "                                     pix_dim),\n",
    "                                    np.uint8)\n",
    "            else:\n",
    "                norm_img = np.zeros((self.height,\n",
    "                                     self.width),\n",
    "                                    np.uint8)\n",
    "            ret_img = self.put_img_into_center(norm_img, ret_img)\n",
    "        return ret_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict(test_image, caffe_cls_number, caffe_cls_region):\n",
    "    #读取\n",
    "    #test_image = \"/opt/plateRec/example/example_3.jpg\"\n",
    "    raw_color_img = plt.imread(test_image)\n",
    "    #plt.figure(figsize=(15,10))\n",
    "\n",
    "    #放大\n",
    "    resize_keep_ratio = PreprocessResizeKeepRatio(1024, 1024)\n",
    "    color_img = resize_keep_ratio.do(raw_color_img)\n",
    "    #plt.figure(figsize=(15,10))\n",
    "    #plt.imshow(color_img)\n",
    "    #灰度\n",
    "    gray_image = cv2.cvtColor(color_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    _, adaptive_image = cv2.threshold(\n",
    "            gray_image,\n",
    "            120,\n",
    "            255,\\\n",
    "            cv2.THRESH_BINARY)\n",
    "    \n",
    "    vertical_peek_ranges2d = []\n",
    "    horizontal_sum = np.sum(adaptive_image, axis=1)\n",
    "    peek_ranges = extract_peek_ranges_from_array_x(horizontal_sum)\n",
    "    \n",
    "     \n",
    "\n",
    "    vertical_sum = np.sum(adaptive_image, axis=0)    \n",
    "    \n",
    "    vertical_peek_ranges2d = crop_direct(peek_ranges, adaptive_image, debug = False) \n",
    "    draw_rectangle(color_img, peek_ranges, vertical_peek_ranges2d)\n",
    "  \n",
    "    char_imgs_region = []\n",
    "    char_imgs_number = []\n",
    "    crop_zeros = PreprocessCropZeros()\n",
    "    resize_keep_ratio = PreprocessResizeKeepRatioFillBG(\n",
    "        norm_width, norm_height, fill_bg=False, margin=4)\n",
    "    for i, peek_range in enumerate(peek_ranges):\n",
    "        for j,vertical_range in enumerate(vertical_peek_ranges2d[i]):\n",
    "            x = vertical_range[0]\n",
    "            y = peek_range[0]\n",
    "            w = vertical_range[1] - x\n",
    "            h = peek_range[1] - y\n",
    "            if j == 0: # 第一个字符\n",
    "                char_img_region = adaptive_image[y:y+h+1, x:x+w+1]\n",
    "                char_img_region = crop_zeros.do(char_img_region)\n",
    "                char_img_region = resize_keep_ratio.do(char_img_region)\n",
    "                \n",
    "                char_imgs_region.append(char_img_region)\n",
    "            else:               \n",
    "                char_img_number = adaptive_image[y:y+h+1, x:x+w+1]\n",
    "                char_img_number = crop_zeros.do(char_img_number)\n",
    "                char_img_number = resize_keep_ratio.do(char_img_number)\n",
    "                char_imgs_number.append(char_img_number)\n",
    "\n",
    "    np_char_imgs_region = np.asarray(char_imgs_region)\n",
    "    np_char_imgs_region = np_char_imgs_region / 255.0\n",
    "    np_char_imgs_number = np.asarray(char_imgs_number)\n",
    "    np_char_imgs_number = np_char_imgs_number / 255.0\n",
    "    \n",
    "   \n",
    "    output_tag_to_max_proba_number = caffe_cls_number.predict_cv2_imgs(np_char_imgs_number)\n",
    "    output_tag_to_max_proba_region = caffe_cls_region.predict_cv2_imgs(np_char_imgs_region)\n",
    "    ocr_res_region = \"\"\n",
    "    for item in output_tag_to_max_proba_region:\n",
    "        ocr_res_region += item[0][0]  \n",
    "    ocr_res_number = \"\"\n",
    "    for item in output_tag_to_max_proba_number:\n",
    "            ocr_res_number += item[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80 ms, sys: 10 ms, total: 90 ms\n",
      "Wall time: 94.7 ms\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 75 ms\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 64.3 ms\n",
      "CPU times: user 70 ms, sys: 0 ns, total: 70 ms\n",
      "Wall time: 61.9 ms\n",
      "CPU times: user 80 ms, sys: 10 ms, total: 90 ms\n",
      "Wall time: 94.9 ms\n",
      "CPU times: user 50 ms, sys: 0 ns, total: 50 ms\n",
      "Wall time: 54.5 ms\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 55.8 ms\n",
      "CPU times: user 90 ms, sys: 0 ns, total: 90 ms\n",
      "Wall time: 87.8 ms\n",
      "CPU times: user 50 ms, sys: 10 ms, total: 60 ms\n",
      "Wall time: 60.7 ms\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 57.4 ms\n",
      "CPU times: user 100 ms, sys: 0 ns, total: 100 ms\n",
      "Wall time: 98.1 ms\n",
      "CPU times: user 50 ms, sys: 10 ms, total: 60 ms\n",
      "Wall time: 64.6 ms\n",
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 63.4 ms\n",
      "CPU times: user 90 ms, sys: 10 ms, total: 100 ms\n",
      "Wall time: 98 ms\n",
      "CPU times: user 80 ms, sys: 0 ns, total: 80 ms\n",
      "Wall time: 80.6 ms\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    norm_width = 64\n",
    "    norm_height = 64\n",
    "    test_path = '/workspace/plateRec/test/'\n",
    "    \n",
    "    base_dir_number = \"/workspace/plateRec/number\"\n",
    "    model_def_number = os.path.join(base_dir_number, \"lenet.prototxt\")\n",
    "    model_weights_number = os.path.join(base_dir_number, \"lenet_iter_1000.caffemodel\")\n",
    "    y_tag_json_path_number = os.path.join(base_dir_number, \"y_tag.json\")\n",
    "    caffe_cls_number = CaffeCls(model_def_number, model_weights_number, y_tag_json_path_number)\n",
    "    \n",
    "    base_dir_region = \"/workspace/plateRec/region\"\n",
    "    model_def_region = os.path.join(base_dir_region, \"lenet.prototxt\")\n",
    "    model_weights_region = os.path.join(base_dir_region, \"lenet_iter_1000.caffemodel\")\n",
    "    y_tag_json_path_region = os.path.join(base_dir_region, \"y_tag.json\")\n",
    "    caffe_cls_region = CaffeCls(model_def_region, model_weights_region, y_tag_json_path_region)\n",
    "    \n",
    "    for test_image in os.listdir(test_path):\n",
    "        %time test_predict(test_image=test_path+test_image, caffe_cls_number=caffe_cls_number, caffe_cls_region=caffe_cls_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
